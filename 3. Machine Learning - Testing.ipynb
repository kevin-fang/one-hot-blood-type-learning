{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import collections\n",
    "import os\n",
    "import seaborn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printCoefs(classifier):\n",
    "    # retrieve all the nonzero coefficients and zip them with their respective indices\n",
    "    nonzeroes = np.nonzero(classifier.coef_[0])[0]\n",
    "    coefs = zip(nonzeroes, classifier.coef_[0][nonzeroes])\n",
    "\n",
    "    # sort the coefficients by their value, instead of index\n",
    "    coefs.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    for coef in coefs[:50]:\n",
    "        print coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded = np.load(\"./npy_data/data_encoded_d.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blood_types = np.load('./npy_data/blood_types.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(blood_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded, blood_types, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(penalty='l1', \n",
    "                    class_weight='balanced', \n",
    "                    alpha=.3,\n",
    "                    l1_ratio=1,\n",
    "                    learning_rate='optimal', \n",
    "                    tol=1e-6,\n",
    "                    max_iter=200,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 6281.25, NNZs: 27, Bias: 0.038562, T: 63, Avg. loss: 117576.363361\n",
      "Total training time: 17.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6327.77, NNZs: 6, Bias: -0.236687, T: 126, Avg. loss: 0.194710\n",
      "Total training time: 35.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6351.63, NNZs: 8, Bias: -0.202158, T: 189, Avg. loss: 0.144560\n",
      "Total training time: 54.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6361.62, NNZs: 6, Bias: -0.244740, T: 252, Avg. loss: 0.092730\n",
      "Total training time: 73.61 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6367.89, NNZs: 6, Bias: -0.259511, T: 315, Avg. loss: 0.089529\n",
      "Total training time: 91.85 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6372.23, NNZs: 6, Bias: -0.265300, T: 378, Avg. loss: 0.093119\n",
      "Total training time: 111.20 seconds.\n",
      "Convergence after 6 epochs took 111.27 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.3, average=False, class_weight='balanced', epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=1, learning_rate='optimal',\n",
       "       loss='hinge', max_iter=200, n_iter=None, n_jobs=1, penalty='l1',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=1e-06, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'printCoefs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-668899372fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintCoefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'printCoefs' is not defined"
     ]
    }
   ],
   "source": [
    "printCoefs(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.9375\n"
     ]
    }
   ],
   "source": [
    "linear = LinearSVC(penalty='l1', class_weight='balanced', C=.06, dual=False, verbose=1, max_iter=2500)\n",
    "linear.fit(X_train, y_train)\n",
    "print(accuracy_score(y_test, linear.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(linear.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_cv = SGDClassifier(penalty='l1', \n",
    "                    class_weight='balanced', \n",
    "                    warm_start=False,\n",
    "                    alpha=3,\n",
    "                    l1_ratio=1,\n",
    "                    learning_rate='optimal', \n",
    "                    max_iter=5,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 6001.24, NNZs: 6, Bias: 0.080259, T: 71, Avg. loss: 21298.880332\n",
      "Total training time: 23.94 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6087.43, NNZs: 6, Bias: -0.257098, T: 142, Avg. loss: 0.407446\n",
      "Total training time: 46.74 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6113.98, NNZs: 5, Bias: -0.334069, T: 213, Avg. loss: 0.155360\n",
      "Total training time: 69.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6125.67, NNZs: 5, Bias: -0.384188, T: 284, Avg. loss: 0.130792\n",
      "Total training time: 90.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6133.16, NNZs: 5, Bias: -0.415039, T: 355, Avg. loss: 0.126522\n",
      "Total training time: 112.54 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6142.92, NNZs: 4, Bias: 0.000412, T: 71, Avg. loss: 3533.704277\n",
      "Total training time: 21.47 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6229.65, NNZs: 4, Bias: -0.285743, T: 142, Avg. loss: 0.271008\n",
      "Total training time: 46.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6252.23, NNZs: 3, Bias: -0.293039, T: 213, Avg. loss: 0.121583\n",
      "Total training time: 67.41 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6263.42, NNZs: 3, Bias: -0.315425, T: 284, Avg. loss: 0.112056\n",
      "Total training time: 88.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6270.41, NNZs: 3, Bias: -0.306706, T: 355, Avg. loss: 0.106333\n",
      "Total training time: 110.50 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5643.49, NNZs: 1, Bias: -0.149495, T: 71, Avg. loss: 115269.655878\n",
      "Total training time: 20.78 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5761.38, NNZs: 7, Bias: -0.146166, T: 142, Avg. loss: 0.719718\n",
      "Total training time: 48.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5789.79, NNZs: 7, Bias: -0.287236, T: 213, Avg. loss: 0.193550\n",
      "Total training time: 71.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5803.49, NNZs: 6, Bias: -0.259365, T: 284, Avg. loss: 0.137732\n",
      "Total training time: 93.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5811.35, NNZs: 5, Bias: -0.292088, T: 355, Avg. loss: 0.112446\n",
      "Total training time: 115.31 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6331.15, NNZs: 414, Bias: 0.057151, T: 71, Avg. loss: 287504.066112\n",
      "Total training time: 18.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6356.76, NNZs: 9, Bias: -0.173130, T: 142, Avg. loss: 0.159099\n",
      "Total training time: 33.87 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6378.62, NNZs: 7, Bias: -0.223478, T: 213, Avg. loss: 0.150545\n",
      "Total training time: 55.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6391.12, NNZs: 7, Bias: -0.244086, T: 284, Avg. loss: 0.145037\n",
      "Total training time: 78.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6398.21, NNZs: 5, Bias: -0.267045, T: 355, Avg. loss: 0.120787\n",
      "Total training time: 98.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6662.15, NNZs: 2746, Bias: 0.083591, T: 71, Avg. loss: 294492.808923\n",
      "Total training time: 19.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6688.23, NNZs: 15, Bias: -0.040159, T: 142, Avg. loss: 0.714760\n",
      "Total training time: 33.97 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6700.50, NNZs: 7, Bias: -0.369025, T: 213, Avg. loss: 0.136627\n",
      "Total training time: 51.93 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6711.09, NNZs: 5, Bias: -0.469326, T: 284, Avg. loss: 0.146597\n",
      "Total training time: 73.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6717.69, NNZs: 5, Bias: -0.473903, T: 355, Avg. loss: 0.126118\n",
      "Total training time: 94.89 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5862.07, NNZs: 4, Bias: -0.102636, T: 71, Avg. loss: 73892.712779\n",
      "Total training time: 19.74 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5957.14, NNZs: 6, Bias: -0.344161, T: 142, Avg. loss: 0.324946\n",
      "Total training time: 43.91 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5981.68, NNZs: 6, Bias: -0.390647, T: 213, Avg. loss: 0.146296\n",
      "Total training time: 64.98 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5993.64, NNZs: 5, Bias: -0.398515, T: 284, Avg. loss: 0.128726\n",
      "Total training time: 86.51 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6001.24, NNZs: 6, Bias: -0.434329, T: 355, Avg. loss: 0.120098\n",
      "Total training time: 108.90 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6848.30, NNZs: 5519, Bias: 0.004840, T: 71, Avg. loss: 298026.477097\n",
      "Total training time: 18.71 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6866.36, NNZs: 32, Bias: 0.018658, T: 142, Avg. loss: 1.418040\n",
      "Total training time: 32.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6883.30, NNZs: 7, Bias: -0.149051, T: 213, Avg. loss: 0.175958\n",
      "Total training time: 53.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6894.86, NNZs: 7, Bias: -0.187058, T: 284, Avg. loss: 0.150056\n",
      "Total training time: 75.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6901.48, NNZs: 5, Bias: -0.185339, T: 355, Avg. loss: 0.121558\n",
      "Total training time: 97.45 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6060.68, NNZs: 4, Bias: -0.146779, T: 71, Avg. loss: 22064.397863\n",
      "Total training time: 20.75 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6144.45, NNZs: 5, Bias: -0.310521, T: 142, Avg. loss: 0.208273\n",
      "Total training time: 43.62 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6166.25, NNZs: 5, Bias: -0.374540, T: 213, Avg. loss: 0.094193\n",
      "Total training time: 63.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6177.34, NNZs: 5, Bias: -0.414529, T: 284, Avg. loss: 0.088051\n",
      "Total training time: 85.40 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6184.48, NNZs: 4, Bias: -0.403111, T: 355, Avg. loss: 0.089384\n",
      "Total training time: 106.30 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5849.08, NNZs: 11, Bias: -0.027153, T: 71, Avg. loss: 246430.917121\n",
      "Total training time: 19.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5925.67, NNZs: 9, Bias: -0.288933, T: 142, Avg. loss: 0.278281\n",
      "Total training time: 41.76 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5955.52, NNZs: 9, Bias: -0.226746, T: 213, Avg. loss: 0.221069\n",
      "Total training time: 64.35 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5968.77, NNZs: 9, Bias: -0.263632, T: 284, Avg. loss: 0.160346\n",
      "Total training time: 87.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5976.38, NNZs: 7, Bias: -0.293382, T: 355, Avg. loss: 0.148740\n",
      "Total training time: 108.85 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5810.33, NNZs: 6, Bias: -0.348950, T: 72, Avg. loss: 42982.306927\n",
      "Total training time: 20.99 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5900.80, NNZs: 6, Bias: -0.267461, T: 144, Avg. loss: 0.208934\n",
      "Total training time: 43.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5923.40, NNZs: 4, Bias: -0.298190, T: 216, Avg. loss: 0.100521\n",
      "Total training time: 64.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5934.28, NNZs: 4, Bias: -0.311297, T: 288, Avg. loss: 0.089700\n",
      "Total training time: 85.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5940.80, NNZs: 4, Bias: -0.287000, T: 360, Avg. loss: 0.090170\n",
      "Total training time: 105.46 seconds.\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(sgd_cv, encoded, blood_types, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9482142857142858, 0.0846850407241384)\n"
     ]
    }
   ],
   "source": [
    "print(cv_score.mean(), cv_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', dual=False, C=.5, verbose=1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14151619"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.abs(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time for classifier takes approximately 7 minutes * n_estimators\n",
    "bag = BaggingClassifier(base_estimator=clf, n_estimators=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=1, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=3, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in (classifier.coef_[0] > 1e-04):\n",
    "    if not i == False:\n",
    "        print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ones = np.nonzero(blood_types)[0]\n",
    "np.random.shuffle(ones)\n",
    "zeros = np.where(blood_types == 0)[0]\n",
    "keep_idx = np.concatenate((zeros, ones[0:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded[keep_idx], blood_types[keep_idx], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve all the nonzero coefficients and zip them with their respective indices\n",
    "nonzeroes = np.nonzero(svc.coef_[0])[0]\n",
    "coefs = zip(nonzeroes, svc.coef_[0][nonzeroes])\n",
    "\n",
    "# sort the coefficients by their value, instead of index\n",
    "coefs.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "for coef in coefs:\n",
    "    print coef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
