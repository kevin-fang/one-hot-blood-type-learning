{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import collections\n",
    "import os\n",
    "import seaborn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printCoefs(classifier):\n",
    "    # retrieve all the nonzero coefficients and zip them with their respective indices\n",
    "    nonzeroes = np.nonzero(classifier.coef_[0])[0]\n",
    "    coefs = zip(nonzeroes, classifier.coef_[0][nonzeroes])\n",
    "\n",
    "    # sort the coefficients by their value, instead of index\n",
    "    coefs.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    for coef in coefs[:50]:\n",
    "        print coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded = np.load(\"./npy_data/data_encoded_d.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blood_types = np.load('./npy_data/blood_types.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(blood_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded, blood_types, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 25019446)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(penalty='l1', \n",
    "                    class_weight={0: .85, 1: 1.25},#'balanced', \n",
    "                    alpha=.28,\n",
    "                    l1_ratio=1,\n",
    "                    learning_rate='optimal', \n",
    "                    tol=1e-6,\n",
    "                    max_iter=200,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7efc5fad74b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/kfang/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7efc5fad74b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/kfang/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'plt = plot_learning_curve(sgd, \"Learning Curve: ...ncoded, blood_types, ylim=(0.05, 1000), n_jobs=4)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 24, 15, 57, 53, 57916, tzinfo=tzlocal()), 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'session': '5F990CD8D69E41689CD5096DF3F0AFE9', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['5F990CD8D69E41689CD5096DF3F0AFE9']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'plt = plot_learning_curve(sgd, \"Learning Curve: ...ncoded, blood_types, ylim=(0.05, 1000), n_jobs=4)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 24, 15, 57, 53, 57916, tzinfo=tzlocal()), 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'session': '5F990CD8D69E41689CD5096DF3F0AFE9', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['5F990CD8D69E41689CD5096DF3F0AFE9'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'plt = plot_learning_curve(sgd, \"Learning Curve: ...ncoded, blood_types, ylim=(0.05, 1000), n_jobs=4)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 24, 15, 57, 53, 57916, tzinfo=tzlocal()), 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'session': '5F990CD8D69E41689CD5096DF3F0AFE9', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-7-05ef39efaebe>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7efc549cf390, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7efc58bf6c30, file \"<ipython-input-7-05ef39efaebe>\", line 1>\n        result = <ExecutionResult object at 7efc549cf390, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7efc58bf6c30, file \"<ipython-input-7-05ef39efaebe>\", line 1>, result=<ExecutionResult object at 7efc549cf390, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7efc58bf6c30, file \"<ipython-input-7-05ef39efaebe>\", line 1>\n        self.user_global_ns = {'In': ['', u\"from sklearn.svm import LinearSVC\\nfrom sklear...linear_model import SGDClassifier\\nseaborn.set()\", u'def printCoefs(classifier):\\n    # retrieve al...n    for coef in coefs[:50]:\\n        print coef', u'encoded = np.load(\"./npy_data/data_encoded_d.npy\")', u\"blood_types = np.load('./npy_data/blood_types.npy')\", u\"sgd = SGDClassifier(penalty='l1', \\n          ...   max_iter=200,\\n                    verbose=1)\", u'from sklearn.model_selection import learning_c...\")\\n\\n    plt.legend(loc=\"best\")\\n    return plt', u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, ...}\n        self.user_ns = {'In': ['', u\"from sklearn.svm import LinearSVC\\nfrom sklear...linear_model import SGDClassifier\\nseaborn.set()\", u'def printCoefs(classifier):\\n    # retrieve al...n    for coef in coefs[:50]:\\n        print coef', u'encoded = np.load(\"./npy_data/data_encoded_d.npy\")', u\"blood_types = np.load('./npy_data/blood_types.npy')\", u\"sgd = SGDClassifier(penalty='l1', \\n          ...   max_iter=200,\\n                    verbose=1)\", u'from sklearn.model_selection import learning_c...\")\\n\\n    plt.legend(loc=\"best\")\\n    return plt', u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/data-sdc/kfang/one_hot_blood_type/<ipython-input-7-05ef39efaebe> in <module>()\n----> 1 plt = plot_learning_curve(sgd, \"Learning Curve: SGDClassifier\", encoded, blood_types, ylim=(0.05, 1000), n_jobs=4)\n\n...........................................................................\n/data-sdc/kfang/one_hot_blood_type/<ipython-input-6-2950dde06f95> in plot_learning_curve(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), title='Learning Curve: SGDClassifier', X=array([[0., 1., 1., ..., 0., 1., 0.],\n       [0...., 1., 0.],\n       [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), ylim=(0.05, 1000), cv=None, n_jobs=4, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]))\n     46     if ylim is not None:\n     47         plt.ylim(*ylim)\n     48     plt.xlabel(\"Training examples\")\n     49     plt.ylabel(\"Score\")\n     50     train_sizes, train_scores, test_scores = learning_curve(\n---> 51         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n     52     train_scores_mean = np.mean(train_scores, axis=1)\n     53     train_scores_std = np.std(train_scores, axis=1)\n     54     test_scores_mean = np.mean(test_scores, axis=1)\n     55     test_scores_std = np.std(test_scores, axis=1)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.py in learning_curve(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), X=array([[0., 1., 1., ..., 0., 1., 0.],\n       [0...., 1., 0.],\n       [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), groups=None, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]), cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), scoring=None, exploit_incremental_learning=False, n_jobs=4, pre_dispatch='all', verbose=0, shuffle=False, random_state=None)\n   1123                 train_test_proportions.append((train[:n_train_samples], test))\n   1124 \n   1125         out = parallel(delayed(_fit_and_score)(\n   1126             clone(estimator), X, y, scorer, train, test,\n   1127             verbose, parameters=None, fit_params=None, return_train_score=True)\n-> 1128             for train, test in train_test_proportions)\n        train = array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 43, 44, 45, 46, 47, 48, 50, 54,\n       57, 59])\n        test = array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])\n        train_test_proportions = [(array([24, 25, 29, 30, 31]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3...     44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 57, 58, 59, 60,\n       61, 62, 63, 64, 65, 66]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 69, 70, 71, 72, 73, 74, 75, 76, 77,\n       78]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([0, 1, 2, 3, 4]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...     17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 49]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 53, 55, 56, 58,\n       60, 61, 62, 63, 64, 65]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 68, 69, 70, 71, 72, 73, 74, 75, 76,\n       77]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([0, 1, 2, 3, 4]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...     17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 42, 43, 44, 45, 46, 47, 48, 50, 54,\n       57]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78]))]\n   1129         out = np.array(out)\n   1130         n_cv_folds = out.shape[0] // n_unique_ticks\n   1131         out = out.reshape(n_cv_folds, n_unique_ticks, 2)\n   1132 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Fri Aug 24 15:58:56 2018\nPID: 76021                                   Python 2.7.12: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), <function _passthrough_scorer>, array([24, 25, 29, 30, 31]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28]), 0)\n        kwargs = {'fit_params': None, 'parameters': None, 'return_train_score': True}\n        self.items = [(<function _fit_and_score>, (SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), <function _passthrough_scorer>, array([24, 25, 29, 30, 31]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28]), 0), {'fit_params': None, 'parameters': None, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), X=memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), scorer=<function _passthrough_scorer>, train=array([24, 25, 29, 30, 31]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    443     if parameters is not None:\n    444         estimator.set_params(**parameters)\n    445 \n    446     start_time = time.time()\n    447 \n--> 448     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False)\n        X = memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]])\n        y = array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1])\n        train = array([24, 25, 29, 30, 31])\n    449     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    450 \n    451     is_multimetric = not callable(scorer)\n    452     n_scorers = len(scorer.keys()) if is_multimetric else 1\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), X=memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), indices=array([24, 25, 29, 30, 31]), train_indices=None)\n    195         if train_indices is None:\n    196             X_subset = X[np.ix_(indices, indices)]\n    197         else:\n    198             X_subset = X[np.ix_(indices, train_indices)]\n    199     else:\n--> 200         X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]])\n        indices = array([24, 25, 29, 30, 31])\n    201 \n    202     if y is not None:\n    203         y_subset = safe_indexing(y, indices)\n    204     else:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py in safe_indexing(X=memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), indices=array([24, 25, 29, 30, 31]))\n    155             return X.copy().iloc[indices]\n    156     elif hasattr(X, \"shape\"):\n    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    158                                    indices.dtype.kind == 'i'):\n    159             # This is often substantially faster than X[indices]\n--> 160             return X.take(indices, axis=0)\n        X.take = <built-in method take of memmap object>\n        indices = array([24, 25, 29, 30, 31])\n    161         else:\n    162             return X[indices]\n    163     else:\n    164         return [X[idx] for idx in indices]\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-05ef39efaebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Learning Curve: SGDClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblood_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-2950dde06f95>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     train_sizes, train_scores, test_scores = learning_curve(\n\u001b[0;32m---> 51\u001b[0;31m         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             verbose, parameters=None, fit_params=None, return_train_score=True)\n\u001b[0;32m-> 1128\u001b[0;31m             for train, test in train_test_proportions)\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mn_cv_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn_unique_ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7efc5fad74b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/kfang/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7efc5fad74b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/kfang/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/data-sdc/kfang/.local/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'plt = plot_learning_curve(sgd, \"Learning Curve: ...ncoded, blood_types, ylim=(0.05, 1000), n_jobs=4)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 24, 15, 57, 53, 57916, tzinfo=tzlocal()), 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'session': '5F990CD8D69E41689CD5096DF3F0AFE9', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['5F990CD8D69E41689CD5096DF3F0AFE9']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'plt = plot_learning_curve(sgd, \"Learning Curve: ...ncoded, blood_types, ylim=(0.05, 1000), n_jobs=4)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 24, 15, 57, 53, 57916, tzinfo=tzlocal()), 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'session': '5F990CD8D69E41689CD5096DF3F0AFE9', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['5F990CD8D69E41689CD5096DF3F0AFE9'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'plt = plot_learning_curve(sgd, \"Learning Curve: ...ncoded, blood_types, ylim=(0.05, 1000), n_jobs=4)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 24, 15, 57, 53, 57916, tzinfo=tzlocal()), 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'session': '5F990CD8D69E41689CD5096DF3F0AFE9', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0A4B34BADEE6447387D0036C27C66ED2', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-7-05ef39efaebe>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7efc549cf390, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7efc58bf6c30, file \"<ipython-input-7-05ef39efaebe>\", line 1>\n        result = <ExecutionResult object at 7efc549cf390, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/kfang/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7efc58bf6c30, file \"<ipython-input-7-05ef39efaebe>\", line 1>, result=<ExecutionResult object at 7efc549cf390, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7efc58bf6c30, file \"<ipython-input-7-05ef39efaebe>\", line 1>\n        self.user_global_ns = {'In': ['', u\"from sklearn.svm import LinearSVC\\nfrom sklear...linear_model import SGDClassifier\\nseaborn.set()\", u'def printCoefs(classifier):\\n    # retrieve al...n    for coef in coefs[:50]:\\n        print coef', u'encoded = np.load(\"./npy_data/data_encoded_d.npy\")', u\"blood_types = np.load('./npy_data/blood_types.npy')\", u\"sgd = SGDClassifier(penalty='l1', \\n          ...   max_iter=200,\\n                    verbose=1)\", u'from sklearn.model_selection import learning_c...\")\\n\\n    plt.legend(loc=\"best\")\\n    return plt', u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, ...}\n        self.user_ns = {'In': ['', u\"from sklearn.svm import LinearSVC\\nfrom sklear...linear_model import SGDClassifier\\nseaborn.set()\", u'def printCoefs(classifier):\\n    # retrieve al...n    for coef in coefs[:50]:\\n        print coef', u'encoded = np.load(\"./npy_data/data_encoded_d.npy\")', u\"blood_types = np.load('./npy_data/blood_types.npy')\", u\"sgd = SGDClassifier(penalty='l1', \\n          ...   max_iter=200,\\n                    verbose=1)\", u'from sklearn.model_selection import learning_c...\")\\n\\n    plt.legend(loc=\"best\")\\n    return plt', u'plt = plot_learning_curve(sgd, \"Learning Curve...coded, blood_types, ylim=(0.05, 1000), n_jobs=4)'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {}, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, '_': '', '__': '', '___': '', '__builtin__': <module '__builtin__' (built-in)>, '__builtins__': <module '__builtin__' (built-in)>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/data-sdc/kfang/one_hot_blood_type/<ipython-input-7-05ef39efaebe> in <module>()\n----> 1 plt = plot_learning_curve(sgd, \"Learning Curve: SGDClassifier\", encoded, blood_types, ylim=(0.05, 1000), n_jobs=4)\n\n...........................................................................\n/data-sdc/kfang/one_hot_blood_type/<ipython-input-6-2950dde06f95> in plot_learning_curve(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), title='Learning Curve: SGDClassifier', X=array([[0., 1., 1., ..., 0., 1., 0.],\n       [0...., 1., 0.],\n       [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), ylim=(0.05, 1000), cv=None, n_jobs=4, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]))\n     46     if ylim is not None:\n     47         plt.ylim(*ylim)\n     48     plt.xlabel(\"Training examples\")\n     49     plt.ylabel(\"Score\")\n     50     train_sizes, train_scores, test_scores = learning_curve(\n---> 51         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n     52     train_scores_mean = np.mean(train_scores, axis=1)\n     53     train_scores_std = np.std(train_scores, axis=1)\n     54     test_scores_mean = np.mean(test_scores, axis=1)\n     55     test_scores_std = np.std(test_scores, axis=1)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.py in learning_curve(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), X=array([[0., 1., 1., ..., 0., 1., 0.],\n       [0...., 1., 0.],\n       [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), groups=None, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]), cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), scoring=None, exploit_incremental_learning=False, n_jobs=4, pre_dispatch='all', verbose=0, shuffle=False, random_state=None)\n   1123                 train_test_proportions.append((train[:n_train_samples], test))\n   1124 \n   1125         out = parallel(delayed(_fit_and_score)(\n   1126             clone(estimator), X, y, scorer, train, test,\n   1127             verbose, parameters=None, fit_params=None, return_train_score=True)\n-> 1128             for train, test in train_test_proportions)\n        train = array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 43, 44, 45, 46, 47, 48, 50, 54,\n       57, 59])\n        test = array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])\n        train_test_proportions = [(array([24, 25, 29, 30, 31]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3...     44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 57, 58, 59, 60,\n       61, 62, 63, 64, 65, 66]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 69, 70, 71, 72, 73, 74, 75, 76, 77,\n       78]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28])), (array([0, 1, 2, 3, 4]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...     17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 49]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 53, 55, 56, 58,\n       60, 61, 62, 63, 64, 65]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 68, 69, 70, 71, 72, 73, 74, 75, 76,\n       77]), array([24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 3..., 43,\n       44, 45, 46, 47, 48, 50, 54, 57, 59])), (array([0, 1, 2, 3, 4]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...     17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1..., 42, 43, 44, 45, 46, 47, 48, 50, 54,\n       57]), array([49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 6..., 69,\n       70, 71, 72, 73, 74, 75, 76, 77, 78]))]\n   1129         out = np.array(out)\n   1130         n_cv_folds = out.shape[0] // n_unique_ticks\n   1131         out = out.reshape(n_cv_folds, n_unique_ticks, 2)\n   1132 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Fri Aug 24 15:58:56 2018\nPID: 76021                                   Python 2.7.12: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), <function _passthrough_scorer>, array([24, 25, 29, 30, 31]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28]), 0)\n        kwargs = {'fit_params': None, 'parameters': None, 'return_train_score': True}\n        self.items = [(<function _fit_and_score>, (SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), <function _passthrough_scorer>, array([24, 25, 29, 30, 31]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28]), 0), {'fit_params': None, 'parameters': None, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), X=memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), scorer=<function _passthrough_scorer>, train=array([24, 25, 29, 30, 31]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...,\n       17, 18, 19, 20, 21, 22, 23, 26, 27, 28]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    443     if parameters is not None:\n    444         estimator.set_params(**parameters)\n    445 \n    446     start_time = time.time()\n    447 \n--> 448     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False)\n        X = memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]])\n        y = array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1])\n        train = array([24, 25, 29, 30, 31])\n    449     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    450 \n    451     is_multimetric = not callable(scorer)\n    452     n_scorers = len(scorer.keys()) if is_multimetric else 1\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=SGDClassifier(alpha=0.28, average=False, class_w...fle=True, tol=1e-06, verbose=1, warm_start=False), X=memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), y=array([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,...0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]), indices=array([24, 25, 29, 30, 31]), train_indices=None)\n    195         if train_indices is None:\n    196             X_subset = X[np.ix_(indices, indices)]\n    197         else:\n    198             X_subset = X[np.ix_(indices, train_indices)]\n    199     else:\n--> 200         X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]])\n        indices = array([24, 25, 29, 30, 31])\n    201 \n    202     if y is not None:\n    203         y_subset = safe_indexing(y, indices)\n    204     else:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py in safe_indexing(X=memmap([[0., 1., 1., ..., 0., 1., 0.],\n        [... 1., 0.],\n        [0., 1., 1., ..., 1., 0., 1.]]), indices=array([24, 25, 29, 30, 31]))\n    155             return X.copy().iloc[indices]\n    156     elif hasattr(X, \"shape\"):\n    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    158                                    indices.dtype.kind == 'i'):\n    159             # This is often substantially faster than X[indices]\n--> 160             return X.take(indices, axis=0)\n        X.take = <built-in method take of memmap object>\n        indices = array([24, 25, 29, 30, 31])\n    161         else:\n    162             return X[indices]\n    163     else:\n    164         return [X[idx] for idx in indices]\n\nMemoryError: \n___________________________________________________________________________"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEcCAYAAADgJkIVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc549cfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plot_learning_curve(sgd, \"Learning Curve: SGDClassifier\", encoded, blood_types, ylim=(0.05, 1000), n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_el = SGDClassifier(penalty='elasticnet', \n",
    "                    class_weight='balanced', \n",
    "                    alpha=.28,\n",
    "                    l1_ratio=0.6,\n",
    "                    learning_rate='optimal', \n",
    "                    tol=1e-6,\n",
    "                    max_iter=200,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2475.62, NNZs: 6928, Bias: 0.046718, T: 63, Avg. loss: 120455.441206\n",
      "Total training time: 16.84 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1986.01, NNZs: 24, Bias: 0.067845, T: 126, Avg. loss: 2.091317\n",
      "Total training time: 32.88 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1762.84, NNZs: 28, Bias: -0.051755, T: 189, Avg. loss: 0.267506\n",
      "Total training time: 55.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1613.85, NNZs: 20, Bias: -0.054179, T: 252, Avg. loss: 0.205908\n",
      "Total training time: 75.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1502.78, NNZs: 22, Bias: -0.085741, T: 315, Avg. loss: 0.178381\n",
      "Total training time: 95.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1415.12, NNZs: 20, Bias: -0.126840, T: 378, Avg. loss: 0.153987\n",
      "Total training time: 113.69 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1346.61, NNZs: 19, Bias: -0.111868, T: 441, Avg. loss: 0.157388\n",
      "Total training time: 132.90 seconds.\n",
      "Convergence after 7 epochs took 132.98 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.28, average=False, class_weight='balanced', epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.6, learning_rate='optimal',\n",
       "       loss='hinge', max_iter=200, n_iter=None, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       tol=1e-06, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_el.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2091.97, NNZs: 117, Bias: -0.106338, T: 71, Avg. loss: 68822.464262\n",
      "Total training time: 17.72 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1769.09, NNZs: 16, Bias: -0.227014, T: 142, Avg. loss: 0.381036\n",
      "Total training time: 40.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1563.36, NNZs: 10, Bias: -0.312362, T: 213, Avg. loss: 0.156752\n",
      "Total training time: 59.45 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1429.18, NNZs: 8, Bias: -0.326453, T: 284, Avg. loss: 0.133793\n",
      "Total training time: 81.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1329.87, NNZs: 8, Bias: -0.350923, T: 355, Avg. loss: 0.122433\n",
      "Total training time: 102.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1252.33, NNZs: 5, Bias: -0.356404, T: 426, Avg. loss: 0.121088\n",
      "Total training time: 123.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1190.05, NNZs: 6, Bias: -0.372749, T: 497, Avg. loss: 0.116961\n",
      "Total training time: 143.80 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1137.86, NNZs: 6, Bias: -0.381005, T: 568, Avg. loss: 0.114178\n",
      "Total training time: 165.17 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1093.80, NNZs: 6, Bias: -0.385317, T: 639, Avg. loss: 0.113324\n",
      "Total training time: 185.67 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1055.21, NNZs: 6, Bias: -0.392102, T: 710, Avg. loss: 0.112180\n",
      "Total training time: 206.56 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1021.33, NNZs: 6, Bias: -0.397914, T: 781, Avg. loss: 0.110544\n",
      "Total training time: 227.25 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 990.99, NNZs: 7, Bias: -0.408567, T: 852, Avg. loss: 0.109980\n",
      "Total training time: 248.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 964.28, NNZs: 7, Bias: -0.402549, T: 923, Avg. loss: 0.110019\n",
      "Total training time: 269.40 seconds.\n",
      "Convergence after 13 epochs took 269.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2214.34, NNZs: 3476, Bias: 0.026721, T: 71, Avg. loss: 136935.583085\n",
      "Total training time: 18.81 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1773.01, NNZs: 22, Bias: -0.043483, T: 142, Avg. loss: 0.978111\n",
      "Total training time: 35.81 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1570.05, NNZs: 13, Bias: -0.118328, T: 213, Avg. loss: 0.196228\n",
      "Total training time: 54.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1434.13, NNZs: 12, Bias: -0.145040, T: 284, Avg. loss: 0.156713\n",
      "Total training time: 75.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1335.54, NNZs: 13, Bias: -0.161660, T: 355, Avg. loss: 0.147806\n",
      "Total training time: 97.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1257.10, NNZs: 10, Bias: -0.183708, T: 426, Avg. loss: 0.130816\n",
      "Total training time: 117.75 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1194.43, NNZs: 10, Bias: -0.177558, T: 497, Avg. loss: 0.134877\n",
      "Total training time: 138.74 seconds.\n",
      "Convergence after 7 epochs took 138.83 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2079.91, NNZs: 1285, Bias: 0.461647, T: 71, Avg. loss: 253633.248263\n",
      "Total training time: 17.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1726.93, NNZs: 38, Bias: 0.303887, T: 142, Avg. loss: 1.324857\n",
      "Total training time: 37.92 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1548.22, NNZs: 16, Bias: 0.339822, T: 213, Avg. loss: 0.396614\n",
      "Total training time: 62.32 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1419.53, NNZs: 17, Bias: 0.251388, T: 284, Avg. loss: 0.294317\n",
      "Total training time: 84.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1323.90, NNZs: 21, Bias: 0.197477, T: 355, Avg. loss: 0.225032\n",
      "Total training time: 106.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1247.06, NNZs: 24, Bias: 0.150619, T: 426, Avg. loss: 0.178939\n",
      "Total training time: 127.99 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1184.34, NNZs: 22, Bias: 0.111324, T: 497, Avg. loss: 0.174104\n",
      "Total training time: 148.90 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1133.71, NNZs: 17, Bias: 0.130364, T: 568, Avg. loss: 0.164557\n",
      "Total training time: 170.50 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1090.81, NNZs: 22, Bias: 0.109917, T: 639, Avg. loss: 0.160343\n",
      "Total training time: 192.18 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1052.11, NNZs: 22, Bias: 0.095839, T: 710, Avg. loss: 0.139112\n",
      "Total training time: 213.21 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1018.82, NNZs: 23, Bias: 0.084252, T: 781, Avg. loss: 0.142706\n",
      "Total training time: 234.80 seconds.\n",
      "Convergence after 11 epochs took 234.90 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2239.79, NNZs: 4167, Bias: -0.027774, T: 71, Avg. loss: 137597.725870\n",
      "Total training time: 19.97 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1778.14, NNZs: 26, Bias: -0.101300, T: 142, Avg. loss: 0.926129\n",
      "Total training time: 36.23 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1570.22, NNZs: 15, Bias: -0.188210, T: 213, Avg. loss: 0.161940\n",
      "Total training time: 57.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1432.05, NNZs: 14, Bias: -0.253961, T: 284, Avg. loss: 0.121927\n",
      "Total training time: 78.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1333.00, NNZs: 11, Bias: -0.272762, T: 355, Avg. loss: 0.111030\n",
      "Total training time: 99.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1255.17, NNZs: 12, Bias: -0.301917, T: 426, Avg. loss: 0.106211\n",
      "Total training time: 120.27 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1192.72, NNZs: 7, Bias: -0.295303, T: 497, Avg. loss: 0.101479\n",
      "Total training time: 141.30 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1139.90, NNZs: 9, Bias: -0.332324, T: 568, Avg. loss: 0.102621\n",
      "Total training time: 161.24 seconds.\n",
      "Convergence after 8 epochs took 161.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2325.05, NNZs: 364, Bias: -0.179930, T: 71, Avg. loss: 15285.179833\n",
      "Total training time: 21.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1881.27, NNZs: 12, Bias: -0.218950, T: 142, Avg. loss: 0.295263\n",
      "Total training time: 39.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1663.73, NNZs: 12, Bias: -0.250123, T: 213, Avg. loss: 0.170659\n",
      "Total training time: 59.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1516.40, NNZs: 12, Bias: -0.293842, T: 284, Avg. loss: 0.145320\n",
      "Total training time: 81.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1408.54, NNZs: 11, Bias: -0.317916, T: 355, Avg. loss: 0.129663\n",
      "Total training time: 101.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1326.12, NNZs: 11, Bias: -0.338284, T: 426, Avg. loss: 0.125876\n",
      "Total training time: 122.86 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1258.41, NNZs: 11, Bias: -0.346533, T: 497, Avg. loss: 0.122598\n",
      "Total training time: 143.50 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1202.59, NNZs: 11, Bias: -0.351790, T: 568, Avg. loss: 0.113913\n",
      "Total training time: 164.72 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1154.83, NNZs: 10, Bias: -0.363452, T: 639, Avg. loss: 0.113636\n",
      "Total training time: 186.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1113.37, NNZs: 9, Bias: -0.370079, T: 710, Avg. loss: 0.113443\n",
      "Total training time: 206.37 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1076.93, NNZs: 8, Bias: -0.372409, T: 781, Avg. loss: 0.111958\n",
      "Total training time: 226.85 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1044.65, NNZs: 8, Bias: -0.378159, T: 852, Avg. loss: 0.114184\n",
      "Total training time: 247.23 seconds.\n",
      "Convergence after 12 epochs took 247.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2091.17, NNZs: 444, Bias: -0.031499, T: 71, Avg. loss: 73241.092823\n",
      "Total training time: 20.84 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1728.58, NNZs: 28, Bias: -0.120059, T: 142, Avg. loss: 0.414097\n",
      "Total training time: 40.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1546.07, NNZs: 16, Bias: -0.063312, T: 213, Avg. loss: 0.202389\n",
      "Total training time: 61.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1414.10, NNZs: 16, Bias: -0.126671, T: 284, Avg. loss: 0.193730\n",
      "Total training time: 83.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1316.86, NNZs: 12, Bias: -0.115712, T: 355, Avg. loss: 0.150448\n",
      "Total training time: 103.78 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1241.68, NNZs: 14, Bias: -0.130315, T: 426, Avg. loss: 0.153386\n",
      "Total training time: 125.37 seconds.\n",
      "Convergence after 6 epochs took 125.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2656.35, NNZs: 30728, Bias: -0.000204, T: 71, Avg. loss: 176028.965763\n",
      "Total training time: 19.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2047.54, NNZs: 282, Bias: 0.003318, T: 142, Avg. loss: 5.018884\n",
      "Total training time: 31.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1758.84, NNZs: 23, Bias: -0.092737, T: 213, Avg. loss: 0.123420\n",
      "Total training time: 46.27 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1594.41, NNZs: 15, Bias: -0.063829, T: 284, Avg. loss: 0.166518\n",
      "Total training time: 64.74 seconds.\n",
      "Convergence after 4 epochs took 64.81 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2371.88, NNZs: 1818, Bias: -0.207093, T: 71, Avg. loss: 53262.986228\n",
      "Total training time: 18.43 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1879.24, NNZs: 17, Bias: -0.232040, T: 142, Avg. loss: 0.555727\n",
      "Total training time: 33.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1651.97, NNZs: 11, Bias: -0.288067, T: 213, Avg. loss: 0.136913\n",
      "Total training time: 54.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1502.84, NNZs: 9, Bias: -0.302807, T: 284, Avg. loss: 0.105351\n",
      "Total training time: 74.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1396.36, NNZs: 10, Bias: -0.326190, T: 355, Avg. loss: 0.110414\n",
      "Total training time: 95.36 seconds.\n",
      "Convergence after 5 epochs took 95.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2256.19, NNZs: 2638, Bias: -0.101610, T: 71, Avg. loss: 96838.864608\n",
      "Total training time: 18.93 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1801.05, NNZs: 20, Bias: -0.211226, T: 142, Avg. loss: 0.903626\n",
      "Total training time: 34.98 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1595.56, NNZs: 10, Bias: -0.263422, T: 213, Avg. loss: 0.176330\n",
      "Total training time: 55.45 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1455.87, NNZs: 11, Bias: -0.334239, T: 284, Avg. loss: 0.148983\n",
      "Total training time: 76.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1354.53, NNZs: 10, Bias: -0.332585, T: 355, Avg. loss: 0.132159\n",
      "Total training time: 96.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1274.55, NNZs: 8, Bias: -0.354518, T: 426, Avg. loss: 0.124778\n",
      "Total training time: 117.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1210.46, NNZs: 8, Bias: -0.341302, T: 497, Avg. loss: 0.123459\n",
      "Total training time: 137.32 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1157.28, NNZs: 8, Bias: -0.361275, T: 568, Avg. loss: 0.121967\n",
      "Total training time: 158.85 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1111.63, NNZs: 8, Bias: -0.364297, T: 639, Avg. loss: 0.117692\n",
      "Total training time: 178.54 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1072.27, NNZs: 8, Bias: -0.375503, T: 710, Avg. loss: 0.116040\n",
      "Total training time: 200.35 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1037.62, NNZs: 9, Bias: -0.381491, T: 781, Avg. loss: 0.115866\n",
      "Total training time: 220.20 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1006.40, NNZs: 8, Bias: -0.394540, T: 852, Avg. loss: 0.112687\n",
      "Total training time: 240.83 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 978.97, NNZs: 8, Bias: -0.393807, T: 923, Avg. loss: 0.113856\n",
      "Total training time: 262.61 seconds.\n",
      "Convergence after 13 epochs took 262.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2122.34, NNZs: 22, Bias: -0.073241, T: 72, Avg. loss: 27945.333447\n",
      "Total training time: 21.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1773.52, NNZs: 9, Bias: -0.219437, T: 144, Avg. loss: 0.236620\n",
      "Total training time: 42.12 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1569.49, NNZs: 8, Bias: -0.257876, T: 216, Avg. loss: 0.120367\n",
      "Total training time: 62.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1430.92, NNZs: 9, Bias: -0.284322, T: 288, Avg. loss: 0.110290\n",
      "Total training time: 84.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1331.34, NNZs: 8, Bias: -0.299285, T: 360, Avg. loss: 0.098958\n",
      "Total training time: 104.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1253.80, NNZs: 6, Bias: -0.313291, T: 432, Avg. loss: 0.088063\n",
      "Total training time: 126.54 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1190.86, NNZs: 6, Bias: -0.318896, T: 504, Avg. loss: 0.083600\n",
      "Total training time: 147.89 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1137.88, NNZs: 5, Bias: -0.328005, T: 576, Avg. loss: 0.081426\n",
      "Total training time: 168.39 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1092.85, NNZs: 5, Bias: -0.336368, T: 648, Avg. loss: 0.079093\n",
      "Total training time: 189.17 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1053.85, NNZs: 5, Bias: -0.343957, T: 720, Avg. loss: 0.078907\n",
      "Total training time: 209.40 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1019.71, NNZs: 5, Bias: -0.354208, T: 792, Avg. loss: 0.077174\n",
      "Total training time: 230.74 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 989.28, NNZs: 5, Bias: -0.359900, T: 864, Avg. loss: 0.076343\n",
      "Total training time: 250.63 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 962.01, NNZs: 5, Bias: -0.364929, T: 936, Avg. loss: 0.075782\n",
      "Total training time: 271.50 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 937.57, NNZs: 4, Bias: -0.357421, T: 1008, Avg. loss: 0.076395\n",
      "Total training time: 291.58 seconds.\n",
      "Convergence after 14 epochs took 291.67 seconds\n",
      "(0.9607142857142857, 0.08214285714285714)\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(sgd_el, encoded, blood_types, cv=10, scoring='accuracy')\n",
    "print(cv_score.mean(), cv_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd_el.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14151619, 0.4738850908986042)\n",
      "(14151629, 0.29839267233162114)\n",
      "(14151706, 0.28546882998985745)\n",
      "(14151717, 0.07628014300941253)\n",
      "(14151726, 0.07628014300941253)\n",
      "(14151790, 0.00942448229535414)\n",
      "(23428091, -0.0033133924618367313)\n",
      "(2172641, -0.004068812548888826)\n",
      "(672210, -0.0057361629238993316)\n",
      "(2951602, -0.008790558259495066)\n",
      "(5815439, -0.012866311473481749)\n",
      "(21481203, -0.023351146546680364)\n",
      "(39427, -0.02421235748011162)\n",
      "(39479, -0.02421235748011162)\n",
      "(14151770, -0.04452715897346624)\n",
      "(14151760, -0.04854806249924858)\n",
      "(5815273, -0.1207113767067516)\n",
      "(14151725, -0.15455996851896595)\n",
      "(14151618, -0.47010591181939665)\n"
     ]
    }
   ],
   "source": [
    "printCoefs(sgd_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npy_data/sgd_el.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(sgd_el, \"npy_data/sgd_el.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear = LinearSVC(penalty='l1', class_weight='balanced', C=.06, dual=False, verbose=1, max_iter=2500)\n",
    "linear.fit(X_train, y_train)\n",
    "print(accuracy_score(y_test, linear.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(linear.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_cv = SGDClassifier(penalty='l1', \n",
    "                    class_weight='balanced', \n",
    "                    warm_start=False,\n",
    "                    alpha=3,\n",
    "                    l1_ratio=1,\n",
    "                    learning_rate='optimal', \n",
    "                    max_iter=5,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(sgd_cv, encoded, blood_types, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(cv_score.mean(), cv_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', dual=False, C=.5, verbose=1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.argmax(np.abs(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time for classifier takes approximately 7 minutes * n_estimators\n",
    "bag = BaggingClassifier(base_estimator=clf, n_estimators=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in (classifier.coef_[0] > 1e-04):\n",
    "    if not i == False:\n",
    "        print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ones = np.nonzero(blood_types)[0]\n",
    "np.random.shuffle(ones)\n",
    "zeros = np.where(blood_types == 0)[0]\n",
    "keep_idx = np.concatenate((zeros, ones[0:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded[keep_idx], blood_types[keep_idx], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve all the nonzero coefficients and zip them with their respective indices\n",
    "nonzeroes = np.nonzero(svc.coef_[0])[0]\n",
    "coefs = zip(nonzeroes, svc.coef_[0][nonzeroes])\n",
    "\n",
    "# sort the coefficients by their value, instead of index\n",
    "coefs.sort(key = lambda x: x[1], reverse=True)\n",
    "\n",
    "for coef in coefs:\n",
    "    print coef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
